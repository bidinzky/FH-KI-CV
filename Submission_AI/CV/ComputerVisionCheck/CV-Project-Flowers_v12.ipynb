{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b7514a",
   "metadata": {},
   "source": [
    "# Computer Vision Project - Classification of Flowers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c11103",
   "metadata": {},
   "source": [
    "In this project your objective is to create a model in order to classify flowers. Thiszip file contains all relevant data. \n",
    "\n",
    "1. The data contains two folders: *train* and *test*. The *train* folder consists of 5486-images to use for training while the *test* folder contains 1351-images you can use to test your model in a **train-test-split** validation style. We have omitted another set of 1352 validation images which we will use to benchmark your final models in the last lecture. \n",
    "\n",
    "\n",
    "2. We have provided you with two label files: *train_labels.csv* and *test_labels.csv*. Each file contains the filename of the corresponding image and the class label. In total we have **102 different classes** of flowers.  You can import the label files using the `import_labels()` function provided to you in this notebook.\n",
    "\n",
    "\n",
    "3. Due to the large number of images, there is a good chance that you can not easily fit the entire training and testing data into RAM. We therefore give you an implementation of a `DataGenerator` class that can be used with keras. This class will read in the images from your hard-drive for each batch during during or testing. The class comes with some nice features that could improve your training significantly such as **image resizing**, **data augmentation** and **preprocessing**. Have a look at the code to find out how.\n",
    "\n",
    "    Initialize data generators using labels and image source directory.\n",
    "\n",
    "    `\n",
    "    datagen_train = DataGenerator('train', y_train, batch_size, input_shape, ...)\n",
    "    datagen_test = DataGenerator('test', y_test, batch_size, input_shape, ...)`\n",
    "\n",
    "    Train your model using data generators.\n",
    "\n",
    "    `model.fit(datagen_train, validation_data=datagen_test, ...)`\n",
    "    \n",
    "    \n",
    "4. Select a suitable model for classification. It is up to you to decide all model parameters, such as **number of layers**, **number and size of filter** in each layer, using **pooling** or, **image-size**, **data-augmentation**, **learning rate**, ... \n",
    "\n",
    "\n",
    "5. **Document** your progress and your intermediate results (your failures and improvements). Describe why you selected certain model and training parameters, what worked, what did not work. Store the training history (loss and accuracy) and create corresponding plots. This documentation will be part of your final presentation and will be **graded**.\n",
    "\n",
    "\n",
    "6. Feel free to explore the internet for suitable CNN models and re-use these ideas. If you use certain features we have not touched during the lecture such as Dropout, Residual Learning or Batch Normalization. Prepare a slide in your final presentation to explain in your own (basic) terms what these things to so we can all learn from your experience. **Notice:** Very large models might perform better but will be harder and slower to train. **Do not use a pre-trained model you find online!**\n",
    "\n",
    "\n",
    "7. Prepare a notebook with your model such that we can use it in the final competition. This means, store your trained model using `model.save(...)`. Your saved models can be loaded via `tf.keras.models.load_model(...)`. We will then provide you with a new folder containing images (*validation*) and a file containing labels (*validation_labels.csv*) which have the same structure. Prepare a data generator for this validation data (test it using the test data) and supply it to the \n",
    " `evaluate_model(model, datagen)` function provided to you.\n",
    " \n",
    " Your prepared notebook could look like this:\n",
    " \n",
    "    `... import stuff \n",
    "    ... code to load the stored model ...\n",
    "    y_validation = import_labels('validation_labels.csv')\n",
    "    datagen_validation = DataGenerator('validation', y_validation, batch_size, input_shape)\n",
    "    evaluate_model(model, datagen_validation)`\n",
    "\n",
    "\n",
    "8. Prepare a 15-Minute presentation of your findings and final model presentation. A rough guideline what could be interesting to your audience:\n",
    "    * Explain your models architecture (number of layers, number of total parameters, how long took it to train, ...)\n",
    "    * Compare the training history of your experimentats visually\n",
    "    * Explain your best model (why is it better)\n",
    "    * Why did you take certain decision (parameters, image size, batch size, ...)\n",
    "    * What worked, what did not work (any ideas why?)\n",
    "    * **What did you learn?**\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c22a7ecb-9693-4e42-9076-0af69ce1213b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stefanbeller/Downloads/Submission_AI/ComputerVision\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "#os.chdir(\"Project\")\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53567ea8-66ea-45ec-ba5f-2c3d0e1909de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dde8f70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in label file and return a dictionary {'filename' : label}.\n",
    "#\n",
    "def import_labels(label_file):\n",
    "    labels = dict()\n",
    "\n",
    "    import csv\n",
    "    with open(label_file) as fd:\n",
    "        csvreader = csv.DictReader(fd)\n",
    "\n",
    "        for row in csvreader:\n",
    "            labels[row['filename']] = int(row['label'])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0c678bf-7643-4d7f-a929-908f1a004e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras import mixed_precision\n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffaa6579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#tf.config.set_visible_devices([], 'GPU')\n",
    "#tf.debugging.experimental.enable_dump_debug_info(log_dir, tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, img_root_dir, labels_dict, batch_size, target_dim, preprocess_func=None, use_augmentation=False):\n",
    "        self._labels_dict = labels_dict\n",
    "        self._img_root_dir = img_root_dir\n",
    "        self._batch_size = batch_size\n",
    "        self._target_dim = target_dim\n",
    "        self._preprocess_func = preprocess_func\n",
    "        self._n_classes = len(set(self._labels_dict.values()))\n",
    "        self._fnames_all = list(self._labels_dict.keys())\n",
    "        self._use_augmentation = use_augmentation\n",
    "\n",
    "        if self._use_augmentation:\n",
    "            self._augmentor = image.ImageDataGenerator(\n",
    "                rotation_range=50,\n",
    "                width_shift_range=0.3,\n",
    "                height_shift_range=0.3,\n",
    "                shear_range=0.3,\n",
    "                zoom_range=0.3,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self._fnames_all)) / self._batch_size)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self._indices = np.arange(len(self._fnames_all))\n",
    "        np.random.shuffle(self._indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self._indices[index * self._batch_size:(index+1)*self._batch_size]\n",
    "\n",
    "        fnames = [self._fnames_all[k] for k in indices]\n",
    "        X,Y = self.__load_files__(fnames)\n",
    "\n",
    "        return X,Y\n",
    "\n",
    "    def __load_files__(self, batch_filenames):\n",
    "        X = np.empty((self._batch_size, *self._target_dim, 3))\n",
    "        Y = np.empty((self._batch_size), dtype=int)\n",
    "\n",
    "        for idx, fname in enumerate(batch_filenames):\n",
    "            img_path = os.path.join(self._img_root_dir, fname)\n",
    "            img = image.load_img(img_path, target_size=self._target_dim)\n",
    "            x = image.img_to_array(img)\n",
    "            if self._preprocess_func is not None:\n",
    "                x = self._preprocess_func(x)\n",
    "\n",
    "            X[idx,:] = x \n",
    "            Y[idx] = self._labels_dict[fname]-1\n",
    "\n",
    "        if self._use_augmentation:\n",
    "            it = self._augmentor.flow(X, batch_size=self._batch_size, shuffle=False)\n",
    "            X = it.next()\n",
    "\n",
    "        if self._preprocess_func is not None:\n",
    "            X = self._preprocess_func(X)\n",
    "        return X, tf.keras.utils.to_categorical(Y, num_classes=self._n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f434355-57af-4a78-806c-5e802fe1e612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras import mixed_precision\n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29fb036b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "#y_train = import_labels(\"train_labels.csv\")\n",
    "#y_test = import_labels(\"test_labels.csv\")\n",
    "y_val = import_labels(\"validation_labels.csv\")\n",
    "batch_size= 24\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c36e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14b650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b4623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30da6807",
   "metadata": {},
   "source": [
    "self._augmentor = image.ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62d929e0-21ed-4147-939c-859ef3b127b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_func(x):\n",
    "    x = x/255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f0b3b56-d45c-4ed8-ae14-7bef82b6f05d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#datagen_train = DataGenerator('train', y_train, batch_size, image_size, preprocess_func=preprocess_func, use_augmentation=True)\n",
    "#datagen_test = DataGenerator('test', y_test, 8, image_size, preprocess_func=preprocess_func)\n",
    "datagen_val = DataGenerator(\"validation\", y_val, 8, image_size, preprocess_func=preprocess_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa187b05-70ef-4ab9-bfc1-10794d6ae719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#    initial_learning_rate=0.005,\n",
    "#    decay_steps=20*datagen_train.__len__()/batch_size,\n",
    "#    decay_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1d5730b-373c-443c-896d-ea0d946e7e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def block(before, size):\n",
    "    net = layers.DepthwiseConv2D((3,3),depth_multiplier=size, strides=(1,1), padding=\"same\", use_bias=False, activation='relu')(before)\n",
    "    net = layers.BatchNormalization()(net)\n",
    "    net = layers.Conv2D(size*2, (1, 1),strides=(1,1), padding=\"same\", use_bias=False, activation='relu')(net)\n",
    "    #net = layers.BatchNormalization()(net)\n",
    "    net = layers.Dropout(.3)(net)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb1bb1ab-212e-4dd3-a417-a8be5dfd3496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "def relu_bn(inputs):\n",
    "    relu = layers.ReLU()(inputs)#activity_regularizer=\"l1_l2\"\n",
    "    bn = layers.BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x, downsample, filters, kernel_size=3,i=None,j=None):\n",
    "    y = layers.Conv2D(kernel_size=kernel_size,\n",
    "                      strides=(1 if not downsample else 2),\n",
    "                      filters=filters,\n",
    "                      padding=\"same\",\n",
    "                      name=f\"res_conv1_{i}_{j}\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = layers.Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\",\n",
    "               name=f\"res_conv2_{i}_{j}\")(y)\n",
    "    if downsample:\n",
    "        x = layers.Conv2D(kernel_size=1,\n",
    "                          strides=2,\n",
    "                          filters=filters,\n",
    "                          padding=\"same\",\n",
    "                          name=f\"res_down_{i}_{j}\")(x)\n",
    "    out = layers.add([x,y])\n",
    "    out = layers.ReLU()(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5eea607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def MinMaxPool(t, size=2):\n",
    "    max = layers.MaxPool2D(size)(t)\n",
    "    min = -layers.MaxPool2D(size)(-t)\n",
    "    conv = layers.Conv2D(1, (3,3), (2,2),padding=\"same\")(t)\n",
    "    return layers.Concatenate()([max,min,conv])\n",
    "\n",
    "def block(t, num_filters):\n",
    "    #t = layers.Conv2DTranspose(num_filters, (5,5),strides=(1,1), activation=\"relu\", padding=\"same\")(i)\n",
    "    #t = layers.MaxPool2D(2)(t)\n",
    "    #t = layers.BatchNormalization()(t)\n",
    "    t = layers.SeparableConv2D(num_filters, (5,5),strides=(1,1), activation=\"relu\", padding=\"same\")(t)\n",
    "    #t = layers.MaxPool2D(2)(t)\n",
    "    t = layers.BatchNormalization()(t)\n",
    "    t = layers.Conv2D(num_filters, (5,5),strides=(1,1), activation=\"relu\", padding=\"same\")(t)\n",
    "    #t = layers.MaxPool2D(2)(t)\n",
    "    t = layers.BatchNormalization()(t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "028f3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCT(i,cout):\n",
    "    dconv = layers.Conv2D(i.shape[3], (4,4),strides=(2,2),groups=i.shape[3], padding=\"same\", use_bias=False)(i)\n",
    "    max = layers.MaxPooling2D(2)(i)\n",
    "    min = -layers.MaxPooling2D(2)(-i)\n",
    "    conc = layers.Concatenate()([max,min, dconv])\n",
    "    pconv = layers.Conv2D(cout,(1,1), padding=\"same\", use_bias=False)(conc)\n",
    "    return layers.BatchNormalization()(pconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5db306b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EVE(i,cout):\n",
    "    max = layers.MaxPooling2D(2)(i)\n",
    "    min = -layers.MaxPooling2D(2)(-i)\n",
    "    conc = layers.Concatenate()([max,min])\n",
    "    pconv = layers.Conv2D(cout,(1,1), padding=\"same\", use_bias=False)(conc)\n",
    "    return layers.BatchNormalization()(pconv)\n",
    "\n",
    "def ME(i,cout):\n",
    "    max = layers.MaxPooling2D(2)(i)\n",
    "    pconv = layers.Conv2D(cout,(1,1), padding=\"same\", use_bias=False)(max)\n",
    "    return layers.BatchNormalization()(pconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd2bc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SELN(i):\n",
    "    gavg = layers.GlobalAveragePooling2D()(i)\n",
    "    norm = layers.LayerNormalization()(gavg)\n",
    "    act = layers.Activation(\"sigmoid\")(norm)\n",
    "    mul = layers.multiply([act, i])\n",
    "    return mul\n",
    "\n",
    "def SE(i,ratio):\n",
    "    gavg = layers.GlobalAveragePooling2D()(i)\n",
    "    fc1 = layers.Dense(int(i.shape[3]/ratio), use_bias=False, activation=\"relu\")(gavg)\n",
    "    fc2 = layers.Dense(i.shape[3], use_bias=False, activation=\"sigmoid\")(fc1)\n",
    "    mul = layers.multiply([fc2, i])\n",
    "    return mul\n",
    "\n",
    "def DW(i, dw_s):\n",
    "    dw = layers.Conv2D(i.shape[3], (dw_s,dw_s), groups=i.shape[3], padding=\"same\")(i)\n",
    "    act1 = layers.Activation(\"swish\")(dw)\n",
    "    return act1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "751d266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFSEBV2(i,dw_s):\n",
    "    pconv1 = layers.Conv2D(i.shape[3],(1,1), padding=\"same\", use_bias=False)(i)\n",
    "    bnorm1 = layers.BatchNormalization()(pconv1)\n",
    "    act1 = layers.Activation(\"swish\")(bnorm1)\n",
    "    dconv1 = layers.Conv2D(i.shape[3],(dw_s,dw_s),groups=i.shape[3], padding=\"same\")(act1)\n",
    "    seln1 = SE(dconv1,3)\n",
    "    #seln1 = SELN(dconv1)\n",
    "\n",
    "    add1 = layers.add([seln1, i])\n",
    "    \n",
    "    pconv2 = layers.Conv2D(i.shape[3],(1,1),padding=\"same\", use_bias=False)(add1)\n",
    "    bnorm2 = layers.BatchNormalization()(pconv2)\n",
    "    act2 = layers.Activation(\"swish\")(bnorm2)\n",
    "    dconv2 = layers.Conv2D(i.shape[3],(dw_s,dw_s),groups=i.shape[3], padding=\"same\")(act2)\n",
    "    add2 = layers.add([dconv2, i])\n",
    "    return add2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1add08ca-221c-42f7-9029-708f2514ff25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import layers, losses\n",
    "#https://arxiv.org/ftp/arxiv/papers/2105/2105.09008.pdf\n",
    "def get_model():\n",
    "    num_filters=96\n",
    "    inputs = layers.Input(image_size + (3,))\n",
    "\n",
    "    #t = layers.BatchNormalization()(inputs)\n",
    "    #t = block(t, num_filters)\n",
    "    #t = MinMaxPool(t,2)\n",
    "    #t = block(t, num_filters*4)\n",
    "    #t = MinMaxPool(t,2)\n",
    "    #t = block(t, num_filters*8)\n",
    "    #t = MinMaxPool(t)\n",
    "    #t = block(t, num_filters*16)\n",
    "    inputs = layers.BatchNormalization()(inputs)\n",
    "    t = FCT(inputs,num_filters)\n",
    "    t = DFSEBV2(t,3)\n",
    "    #t = layers.Dropout(.2)(t)\n",
    "    t = EVE(t,num_filters*4)\n",
    "    t = DFSEBV2(t,3)\n",
    "    #t = SELN(t)\n",
    "    #t = layers.Dropout(.2)(t)\n",
    "    for i in range(1,4):\n",
    "        t = ME(t,(num_filters*4)*2**i)\n",
    "        t = DFSEBV2(t,3)\n",
    "        #t = SELN(t)\n",
    "        #t = layers.Dropout(.2)(t)\n",
    "\n",
    "    t = DW(t, 3)\n",
    "    t = layers.GlobalAveragePooling2D()(t)\n",
    "    t = layers.Dropout(.5)(t)\n",
    "    #t = layers.Flatten()(t)\n",
    "    #t = layers.Dense(256, activation=\"relu\")(t)\n",
    "    outputs = layers.Dense(102, activation=\"softmax\", dtype=\"float32\")(t)\n",
    "    #outputs = layers.Dense(102, dtype=\"float32\")(t)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    #model.compile(optimizer=SGD(learning_rate=0.05,nesterov=True), loss=losses.CategoricalCrossentropy(from_logits=False), metrics=[\"accuracy\"])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss=losses.CategoricalCrossentropy(from_logits=False), metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#tuner = kt.RandomSearch(\n",
    "#    get_model,\n",
    "#    objective='val_loss',\n",
    "#    max_trials=5)\n",
    "#model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc9e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb2cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb399c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2df0553-5d76-44f7-bb69-beea0bbdba20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"training_v12.ckpt\",\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "rlr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"loss\",\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    ")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35ee4357-0fb6-45af-80e0-3c5c95ef082f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "#if os.path.exists(\"training_v12.ckpt.index\"):\n",
    "#     model.load_weights(\"training_v12.ckpt\")\n",
    "model = tf.keras.models.load_model(\"model_06_06_2022_v12_92%\")\n",
    "tf.keras.utils.plot_model(model,show_layer_names=False, expand_nested=True, dpi=96, rankdir=\"LR\", to_file=\"model_v13.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94ad920c-652a-47f1-a467-4ef8cd688f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model on dataset\n",
    "#history = model.fit(datagen_train, validation_data=datagen_test, epochs=120,callbacks=[\n",
    "#                                                                          early_stopping,\n",
    "#                                                                          #cp_callback,\n",
    "#                                                                           rlr\n",
    "#                                                                          # ,tensorboard_callback  \n",
    "#                                                                          ])\n",
    "        \n",
    "#tuner.search(datagen_train, epochs=4, validation_data=datagen_test)\n",
    "#best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "597a54cd-24b2-4351-ab1c-0cde9d7d825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig(\"06_06_v12_acc.png\")\n",
    "    # summarize history for loss\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig(\"06_06_v12_loss.png\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd35d225-bc98-4f31-92a0-214a09b4328b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 09:07:52.384274: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 29s 168ms/step - loss: 0.4551 - accuracy: 0.9297\n",
      "test loss, test acc: [0.45506101846694946, 0.9297337532043457]\n"
     ]
    }
   ],
   "source": [
    "#model.save(\"model_06_06_2022_v12_92%\")\n",
    "#best_model.summary()\n",
    "results = model.evaluate(datagen_val)\n",
    "print(\"test loss, test acc:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44084d93-10d0-477e-88d8-c867a8439327",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bfd706a-c4c8-4b25-9b3a-8f8505edef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, to_file=\"model_v12.png\", show_layer_names=False, expand_nested=True, dpi=96, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f8f6c-6337-4552-994b-1ad50255ad17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62ea753f7e5c40da959618c5bbb702665220061772d3bf458531278c9b01fd65"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
